# uol-llama2
docker application for llama-2-7b-chat

make sure you got the docker installed successfully

simply run the following two lines in your command:

`make build`

Input your personal download url from Meta to download the llama-2-7b-chat model.

`make start`

Then, start chatting.



Hints:

1. you must have at least 1 GPU on your machine for 7b models. 2 GPUs for 13b models, and 8 GPU for 30b models.
